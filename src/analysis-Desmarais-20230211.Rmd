---
title: "analysis-Desmarais-20230211"
output: html_document
date: "2023-02-11"
editor_options: 
  chunk_output_type: console
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warnings = FALSE,
                      messages = FALSE)
```

## Introduction

The American National Election Studies (ANES) surveys eligible U.S. voters before and after presidential elections on various topics. For the 2020 pre-election survey, new questions were added on topics such as sexual harassment, health insurance, identity politics, immigration, media trust, institutional legitimacy, campaigns, party images, trade tariffs, and tax policy. Data collection started in August 2020 and ended on election day, November 3rd, 2020.

Ad Fontes Media is a non-partisan group that rates media sources based on their political bias and reliability. The media bias project evaluates individual news articles, TV shows, and radio programs using a three-analyst rating system, each with different political leanings.

![Ad Fontes Chart](../references/images/ad-fontes-chart.png)

The purpose of the analysis is to combine data from the ANES survey with the Ad Fontes Media project to examine variations in empathy, family politics, self-censorship, and sexism based on the media bias and reliability scores of the media consumed by each respondent.

### Research Questions

1. Do responses to questions on empathy and family politics vary by party affiliation?
2. Are responses to questions on empathy and family politics associated with bias and reliability of media outlets?
3. Is there a relationship between responses to questions on empathy and family politics with social media usage?

4. Are any specific media outlets predicitve of empathy or emotion responses?

5. Do more biased media consumers vote in caucuses more often?

## Data

### Variables

#### Emotion

- *V201114* - are things in the country on track
- *V201115* - how hopeful R feels about how things are going in the country
- *V201116* - how afraid R feels about how things are going in the country
- *V201117* - how outraged R feels about how things are going in the country
- *V201118* - how angry R feels about how things are going in the country
- *V201119* - how happy R feels about how things are going in the country
- *V201120* - how worried R feels about how things are going in the country
- *V201121* - how proud R feels about how things are going in the country
- *V201122* - how irritated R feels about how things are going in the country
- *V201123* - how nervous R feels about how things are going in the country

#### Racial empathy

- *V202452* - how often does R have concerned feelings for other racial/ethnic groups
- *V202453* - how often does R try to understand perspective of other racial/ethnic groups
- *V202454* - how often R imagines how they would feel before criticizing other groups
- *V202455* - how often R feels protective of someone due to race or ethnicity

#### Self-censorship

- *V201626* - need to be more sensitive talking or people too easily offended
- *V201627* - how often self censor

#### Sexism

- *V201639* - women interpret innocent remarks as sexist
- *V201640* - women seek to gain power by getting control over men

#### Political violence

- *V201602* - how much do you feel it is justified for people to use violence to pursue their political goals in this country?
- *V201603* - compared to four years ago, do you think violence used to pursue political goals in the United States has:
- *V201604* - has it [increased/decreased] a great deal, a moderate amount, or a little?
- *V201605x* - Summary of V201603 and V201604

#### Discussing politics with family

- *V202451* - how much have political differences hurt relationships w/family
- *V202022* - Do you ever discuss politics with your family or friends?
- *V202023* - How many days in the past week did you talk about politics with family or friends?
- *V202024* - During the past 12 months, have you ever gotten into a political argument with someone, or have you not done this in the past 12 months?

```{r load-libs-and-data, warning = FALSE}
library(tidyverse)

anes <- read_csv("data/raw/anes_timeseries_2020_csv_20220210.csv",
                 show_col_types = FALSE)
```

```{r anes-desc-stats}
dim(anes)
head(anes)
```

Create subsets of the ANES data set for the variables of interest.

```{r anes-subset}
# Pre- (a) and post-election (b) weights
anes_weights <- anes %>%
  select(V200010a:V200010b)

# Party affiliation, registration, and voting
anes_registration <- anes %>%
  select(V201018:V201021) %>%
  select(!V201018z)
         
# Family and emotion, empathy, self-censorship, sexism
anes_emotion <- anes %>%
  select(V201114:V201123, # Emotion about the country
         V202451:V202456, # Family relationships and racial empathy
         V201626:V201627, # Self-censorship
         V201639:V201640, # Sexism
         V201602:V201605x, # Political violence
         V202022:V202024) # Discussing politics

# Pre-election media responses
anes_media <- anes %>%
  select(V201630a:V201630r, # TV programs 1
         V201631a:V201631r, # TV programs 2
         V201633a:V201633r, # Radio programs
         V201634a:V201634c,V201634e:V201634f, V201634h,
         V201634j:V201634q, # Websites not included in online newspapers
         V201636a:V201636d) # Online newspapers

# Post-election social media responses
anes_social_media <- anes %>%
  select(V202541a:V202547) # Note there are post-election
```

### Impute non-respondants

The media variables are coded as:

* -9. Refused
* -5. Interview breakoff (sufficient partial IW)
* -1. Inapplicable
* 0. Not mentioned
* 1. Mentioned

The focus will be on the "Not Mentioned" and "Mentioned" response types, which reflect the respondents' monthly consumption of specific media sources. Other responses will be considered missing and will be filled in as either 0 or 1 using information from other non-response variables in the pre- and post-election survey questions. The imputation technique employed will be Random Forest imputation.

Random Forest imputation is a statistical method used to fill in missing values in a dataset. It uses an ensemble of decision trees (a "forest") to predict missing values. The algorithm works by splitting the dataset into smaller subsets, and building a decision tree for each of these subsets. The final prediction for the missing value is obtained by combining the results of all trees. Random Forest Imputation has the advantage of being more robust to outliers and noise compared to other imputation methods and can handle both continuous and categorical variables.

To simplify the analysis process and reduce computation time, the imputation step has been separated from this document and can be found in the "impute.Rmd" file. The imputed dataset, generated using Random Forest Imputation, is stored in the "data/interim/missForest-imputed.RDS" file and can be accessed there.

The `missForest()` from the `missForest` library will be used to impute the missing values generated above using a random forest model. This approach has the advantage of being able to impute categorical data while handling complex interactions and nonlinear relationships. However, the algorithm has a long computation time, particularly when there are a lot of variables in the dataset.

The function by default will run over 10 iterations and takes a sizeable amount of time with this dataset, so the data was pre-imputed using a parallel backend to save computation time.

The `missForest` algorithm returns a dataframe of the 'best' selected imputed results, in addition to the out-of-box (OOB) proportion of falsely classified (PFC) observations. The OOB-PFC is calculated by predicting on known, unsampled observations to compare against their known values.

```{r read-imputed}
library(missForest) # Load in case of any dependencies when loading a missForest data class
anes_imputed <- readRDS('data/interim/missForest-imputed.RDS')

anes_imputed$OOBerror
```

The OOB-PFC is `r round(anes_imputed$OOBerror[2], 5)`, which can be considered equivalent to ~ 92% accuracy since there are two classes to each of the variables imputed on.

### Bias and Reliability EDA

The following code loads the Ad Fontes Media data and creates an interactive chart displaying the reliability and bias scores for each media source in the ANES dataset that has been scored.

```{r load-ad-fontes-media}
library(plotly)
library(ggrepel)
library(ggchicklet)

adfontes <- read_csv('data/raw/adfontes.csv') %>%
  mutate(Media = factor(ifelse(Media == "ONLINE NEWSPAPER",
                               "WEBSITE",
                               Media))) %>%
  drop_na() %>%
  # Remove duplicates created from combining WEBSITE and ONLINE NEWSPAPER
  filter(Code != 'V201634d',
         Code != 'V201634i',
         Code != 'V201634g')

rectangles <- data.frame(xmin = c(-42, 42),
                         xmax = c(42, 42),
                         ymin = c(0, 16),
                         ymax = c(16, 46))

adfontes_plot <- adfontes %>%
  mutate(Outlet = str_remove(Outlet, '\\s\\(.*\\)')) %>%
  ggplot(aes(x = Bias,
             y = Reliability,
             color = Media,
             label = Outlet)) +
  ggchicklet:::geom_rrect(aes(xmin = -42, xmax = 42,
                              ymin = 0, ymax = 16),
                          fill = NA) +
  geom_point(alpha = 0.75) +
  scale_x_continuous(limits = c(-42, 42),
                     breaks = c(-42, -30, -18, -6, 0, 6, 18, 30, 42)) +
  scale_y_continuous(limits = c(0, 64),
                     breaks = seq(0, 64, 8)) +
  scale_color_manual(values = c("steelblue", "goldenrod", "tomato")) +
  theme_bw()

ggplotly(adfontes_plot) %>%
  layout(legend = list(orientation = "h",
                       x = 0.25,
                       y = -0.2))
```

The scatter plot reveals that radio programs typically have a right-leaning bias and low reliability, while websites tend to have a slight left bias and high reliability. TV programs exhibit a wider range of bias and reliability scores. There is some clustering observed around a slight left bias and high reliability. Additionally, the values appear to follow a curvi-linear trend where reliability scores decrease as left or right bias increases.

The following code will calculate and print the average and median reliability and bias scores for each type of media, as well as the count of media sources with a "left", "right", or "center" bias.

```{r}
adfontes_media_summ <- adfontes %>%
  group_by(Media) %>%
  summarize('Mean Reliability' = mean(Reliability),
            'Median Reliability' = median(Reliability),
            'Mean Bias' = mean(Bias),
            'Median Bias' = median(Bias))

adfontes_media_summ
```

Like the scatter plot above, the analysis of the radio programs shows that they tend to have lower reliability scores and a strong right-leaning bias, compared to other media types.

To explore the correlation between bias and reliability, the absolute values of the bias scores will be used to fit a linear model. The results of this model, including the correlation coefficient and p-value, will then be displayed in a replotted version of the data.

```{r adfontes-bias-rel-corr}
# Create a linear model predicting Reliability by the abs val of Bias
bias_rel_fit <- summary(lm(Reliability ~ abs(Bias),
                   data = adfontes))

adfontes_plot <- adfontes %>%
  ggplot(aes(x = abs(Bias),
             y = Reliability,
             color = Media,
             label = Outlet)) +
  geom_point(alpha = 0.75) +
  geom_abline(slope = bias_rel_fit$coefficients[2, 1],
              intercept = bias_rel_fit$coefficients[1, 1],
              lty = 'dashed') +
  annotate('text',
           x = 22.5,
           y = 40,
           label = paste0('r^2 = ', round(bias_rel_fit$r.squared, 3),
                          '\np < 0.001')) +
  scale_color_manual(values = c("steelblue", "goldenrod", "tomato")) +
  theme_bw() 

ggplotly(adfontes_plot) %>%
  layout(legend = list(orientation = "h",
                       x = 0.25,
                       y = -0.2))
```

The relationship between reliability and bias appears to be strong and linear, as evidenced by the transformation of the curvi-linear distribution of the reliability and bias scores into a strongly linear one upon taking the absolute value of the bias scores. This suggests that there is a strong correlation between reliability and bias, regardless of whether the bias is "left" or "right," and that this relationship remains consistent across all types of media.

The ANES media variables will be limited to only those that have received bias and reliability scores from Ad Fontes Media. This step was not taken prior to imputation as it was believed that the full set of variables could play a crucial role in accurately predicting missing values in the bagged tree imputation process.

The relationship between reliability and bias appears to be strong and linear, as evidenced by the transformation of the curvi-linear distribution of the reliability and bias scores into a strongly linear one upon taking the absolute value of the bias scores. This suggests that there is a strong correlation between reliability and bias, regardless of whether the bias is "left" or "right," and that this relationship remains consistent across all types of media.

The ANES media variables will be limited to only those that have received bias and reliability scores from Ad Fontes Media. This step was not taken prior to imputation as it was believed that the full set of variables could play a crucial role in accurately predicting missing values in the bagged tree imputation process.

```{r keep-adfontes-vars}
# Keep only the media vars that have Reliability and Bias scores
media_codes <- adfontes %>%
  pull(Code)
  
anes_imputed_media <- anes_imputed$ximp %>%
  select(all_of(media_codes)) %>%
  # Convert to character then to numeric to avoid re-coding by going straight from factor to numeric
  mutate(across(everything(), ~ as.numeric(as.character(.))))
```

The total, average, and median Bias and Reliability scores for the media consumed by each participant will be calculated. Bias will also be left as-is so that respondents who consume media equally on both sides can be centered (toward 0).

```{r bias-rel-sum-stats}
# Set 0's in the media vars to NA so they are not calculated and to allow for Bias == 0 to be
# included
anes_imputed_media[anes_imputed_media == 0] <- NA

# Multiply col-wise to get the Bias and Reliability within each column
anes_imputed_media_bias <- anes_imputed_media *
  adfontes$Bias[match(names(anes_imputed_media),
                      adfontes$Code)][col(anes_imputed_media)]

anes_imputed_media_rel <- anes_imputed_media *
  adfontes$Reliability[match(names(anes_imputed_media),
                             adfontes$Code)][col(anes_imputed_media)]

anes_imputed_media <- anes_imputed_media %>%
  mutate(Total_Bias = rowSums(anes_imputed_media_bias,
                              na.rm = TRUE),
         Total_Rel = rowSums(anes_imputed_media_rel,
                             na.rm = TRUE),
         # Get the average Bias and Reliability based on the media consumed for each respondent
         # This will create NaN values for respondents with all 0 values
         Avg_Bias = Total_Bias / rowSums(!is.na(anes_imputed_media_bias)),
         Avg_Rel = Total_Rel / rowSums(!is.na(anes_imputed_media_rel)))

# Get the row-wise median for bias and reliability
# Will return NA in rows without any values
anes_imputed_media$Median_Bias <- apply(anes_imputed_media_bias,
                                        1,
                                        function(x) median(x[x !=0],
                                                           na.rm = TRUE))
anes_imputed_media$Median_Rel <- apply(anes_imputed_media_rel,
                                       1,
                                       function(x) median(x[x != 0],
                                                          na.rm = TRUE))

# Replace NaN and NA values with 0
anes_imputed_media <- anes_imputed_media %>%
  mutate(across(c(Avg_Bias, Avg_Rel),
                ~ replace(., is.nan(.), 0)),
         across(c(Median_Bias, Median_Rel),
                ~ replace(., is.na(.), 0)))

# Reset the NAs to 0
anes_imputed_media[is.na(anes_imputed_media)] <- 0

anes_imputed_media %>%
  select(Total_Bias:Median_Rel) %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x = value)) +
    geom_histogram(bins = 30) +
    facet_wrap(~ name, scales = 'free') +
    theme_classic()
```

As expected, the number of *not mentioned* ('0') values dominates most of the distributions. We should remove any respondents who did not consume any of the medias (have reliability = 0).

```{r}
anes_imputed_media %>%
  select(Total_Bias:Median_Rel) %>%
  filter(Total_Rel != 0) %>%
  pivot_longer(everything()) %>%
  mutate(name = factor(name,
                       levels = c("Avg_Bias", "Median_Bias", "Total_Bias",
                                  "Avg_Rel", "Median_Rel", "Total_Rel"),
                       labels = c('Average Bias', 'Median Bias', 'Total Bias',
                                  'Average Reliability', 'Median Reliability', 'Total Reliability'))) %>%
  ggplot(aes(x = value)) +
    geom_histogram(bins = 30) +
    facet_wrap(~ name, scales = 'free') +
    labs(x = "Value",
         y = "Count") +
    theme_classic()
```

After removal the data is still non-normal, but approachable for modeling. The most normal is *Total Bias*, which centers slightly left and has a right skew.

To get an idea of the distribution of political affiliation for the respondents, a bar plot with the total count for each response is presented below.

```{r}
# Plot the total number of respondents in each political affiliation
anes_registration %>%
  select(V201018) %>%
  group_by(V201018) %>%
  summarize(n = n()) %>%
  ggplot(aes(x = ordered(V201018),
             y = n)) +
    geom_col() +
    scale_x_discrete(labels = c('Refused', 'Dont Know', 'Inapplicable', 'D', 'R', 'I', 'Other')) +
    labs(x = "Party affiliation",
         y = "Count") +
    theme_classic()
```

Nearly half of the respondents did not include a political affiliation, while those who did fell into Democrat, Republican, Independent, or Other in order of decreasing total counts. Only a small amount of respondents refused to answer the question.

To model the empathy responses, a new dataframe will be created that includes each of the four empathy variables, pre- and post-election weights, party registration, and the imputed bias and reliability scores. Additionally, the average and total bias scores will be grouped into either 'left', 'center-left', 'center', 'center-right', or 'right'.

```{r}
anes_empathy_df <- anes_registration %>%
  bind_cols(anes_weights, anes_emotion, anes_imputed_media) %>%
  select(V200010a, # Pre-election weights
         V200010b, # Post-election weights
         V201018, # Party registration
         V202451:V202455, # Empathy
         Total_Bias:last_col()) %>%
  pivot_longer(V202452:V202455,
               names_to = 'empathy',
               values_to = 'value') %>%
  # Filter out non-respondents for empathy questions 
  filter(value > 0,
         # Filter respondents who did not consume any of the media sources, which would have
         # a reliability score = 0
         Avg_Rel != 0) %>%
  mutate(Abs_Bias = abs(Avg_Bias), # New variable with absolute value of bias
         # New variable that indicates direction of bias
         Dir_Bias = factor(case_when(Avg_Bias > 15 ~ 2,
                                     Avg_Bias < -15 ~ -2,
                                     Avg_Bias <= 15 & Avg_Bias > 5 ~ 1, 
                                     Avg_Bias >= -15 & Avg_Bias < -5 ~ -1,
                                     TRUE ~ 0),
                           levels = c(0, -2, -1, 1, 2)),
         Dir_Tot_Bias = factor(case_when(Total_Bias > 75 ~ 2,
                                     Total_Bias < -75 ~ -2,
                                     Total_Bias <= 75 & Total_Bias > 25 ~ 1, 
                                     Total_Bias >= -75 & Total_Bias < -25 ~ -1,
                                     TRUE ~ 0),
                           levels = c(0, -2, -1, 1, 2)),
         value = ordered(value)) # Set the response to an ordered factor
```

Next, the average reliability score will be plotted against their average and total bias scores for each respondent who identified with a political party, which will be identified by color.

```{r}
# Plot Reliability vs Bias for political party affiliation (only R, D, and I)
affil_plt1 <- anes_empathy_df %>%
  select(!c(empathy, value)) %>%
  distinct() %>%
  filter(V201018 %in% c(1, 2, 4, 5),
         Avg_Bias != 0 & Avg_Rel != 0) %>%
  ggplot(aes(x = Avg_Bias,
             y = Avg_Rel,
             color = ordered(V201018))) +
  geom_point(alpha = 0.25) +
  scale_color_manual(values = c('blue', 'red', 'grey50', 'green'),
                     labels = c('Democrat', 'Republican', 'Independent', 'Other')) +
  scale_x_continuous(limits = c(-35, 35)) +
  labs(x = "Average bias",
       y = "Average reliability",
       color = 'Party affiliation') +
  theme_bw() +
  theme(legend.position = 'bottom')

affil_plt2 <- anes_empathy_df %>%
  select(!c(empathy, value)) %>%
  distinct() %>%
  filter(V201018 %in% c(1, 2, 4, 5)) %>%
  ggplot(aes(x = Total_Bias,
             y = Avg_Rel,
             color = ordered(V201018))) +
  geom_point(alpha = 0.25) +
  scale_color_manual(values = c('blue', 'red', 'grey50', 'green'),
                     labels = c('Democrat', 'Republican', 'Independent', 'Other')) +
  scale_x_continuous(limits = c(-250, 250)) +
  labs(x = "Total bias",
       y = "Average reliability",
       color = 'Party affiliation') +
  theme_bw() +
  theme(legend.position = 'bottom')

affil_plt1
affil_plt2
```




```{r}
demo_lm <- anes_empathy_df %>%
  filter(V201018 == 1,
         empathy == 'V202452') %>%
  lm(formula = Avg_Rel ~ abs(Avg_Bias)) %>%
  summary()

repub_lm <- anes_empathy_df %>%
  filter(V201018 == 2,
         empathy == 'V202452') %>%
  lm(formula = Avg_Rel ~ abs(Avg_Bias)) %>%
  summary()

indep_lm <- anes_empathy_df %>%
  filter(V201018 == 4,
         empathy == 'V202452') %>%
  lm(formula = Avg_Rel ~ abs(Avg_Bias)) %>%
  summary()

other_lm <- anes_empathy_df %>%
  filter(V201018 == 5,
         empathy == 'V202452') %>%
  lm(formula = Avg_Rel ~ abs(Avg_Bias)) %>%
  summary()

anes_empathy_df %>%
  filter(V201018 >= 1,
         empathy == 'V202452') %>%
  ggplot(aes(x = abs(Avg_Bias),
             y = Avg_Rel,
             color = ordered(V201018))) +
  geom_point(alpha = 0.25) +
  geom_abline(slope = demo_lm$coefficients[2, 1],
              intercept = demo_lm$coefficients[1, 1],
              lty = 'dashed',
              color = 'blue',
              size = 1) +
  geom_abline(slope = repub_lm$coefficients[2, 1],
              intercept = repub_lm$coefficients[1, 1],
              lty = 'dashed',
              color = 'red',
              size = 1) +
  geom_abline(slope = indep_lm$coefficients[2, 1],
              intercept = indep_lm$coefficients[1, 1],
              lty = 'dashed',
              color = 'grey50',
              size = 1) +
  geom_abline(slope = other_lm$coefficients[2, 1],
              intercept = other_lm$coefficients[1, 1],
              lty = 'dashed',
              color = 'green',
              size = 1) +
  scale_color_manual(values = c('blue', 'red', 'grey50', 'green'),
                     labels = c('Democrat', 'Republican', 'Independent', 'Other')) +
  labs(x = 'Absolute total bias',
       y = 'Average reliability') +
  theme_bw()
```





```{r}
demo_lm <- anes_empathy_df %>%
  filter(V201018 == 1,
         empathy == 'V202452') %>%
  lm(formula = Avg_Rel ~ abs(Total_Bias)) %>%
  summary()

repub_lm <- anes_empathy_df %>%
  filter(V201018 == 2,
         empathy == 'V202452') %>%
  lm(formula = Avg_Rel ~ abs(Total_Bias)) %>%
  summary()

indep_lm <- anes_empathy_df %>%
  filter(V201018 == 4,
         empathy == 'V202452') %>%
  lm(formula = Avg_Rel ~ abs(Total_Bias)) %>%
  summary()

other_lm <- anes_empathy_df %>%
  filter(V201018 == 5,
         empathy == 'V202452') %>%
  lm(formula = Avg_Rel ~ abs(Total_Bias)) %>%
  summary()

anes_empathy_df %>%
  filter(V201018 >= 1,
         empathy == 'V202452') %>%
  ggplot(aes(x = abs(Total_Bias),
             y = Avg_Rel,
             color = ordered(V201018))) +
  geom_point(alpha = 0.25) +
  geom_abline(slope = demo_lm$coefficients[2, 1],
              intercept = demo_lm$coefficients[1, 1],
              lty = 'dashed',
              color = 'blue',
              size = 1) +
  geom_abline(slope = repub_lm$coefficients[2, 1],
              intercept = repub_lm$coefficients[1, 1],
              lty = 'dashed',
              color = 'red',
              size = 1) +
  geom_abline(slope = indep_lm$coefficients[2, 1],
              intercept = indep_lm$coefficients[1, 1],
              lty = 'dashed',
              color = 'grey50',
              size = 1) +
  geom_abline(slope = other_lm$coefficients[2, 1],
              intercept = other_lm$coefficients[1, 1],
              lty = 'dashed',
              color = 'green',
              size = 1) +
  scale_color_manual(values = c('blue', 'red', 'grey50', 'green'),
                     labels = c('Democrat', 'Republican', 'Independent', 'Other')) +
  labs(x = 'Absolute total bias',
       y = 'Average reliability') +
  theme_bw()
  
```




The above plots will be re-plotted with the response to each empathy question colored.

```{r}
# Plot Reliability vs Bias for each empathy var
empathy_plt1 <- anes_empathy_df %>%
  ggplot(aes(x = Avg_Bias,
             y = Avg_Rel,
             color = value)) +
  geom_point(alpha = 0.25) +
  facet_wrap(~ empathy) +
  theme_bw() +
  labs(x = 'Average Bias',
       y = 'Average Reliability') +
  theme(legend.position = 'bottom')

empathy_plt2 <- anes_empathy_df %>%
  ggplot(aes(x = Total_Bias,
             y = Avg_Rel,
             color = value)) +
  geom_point(alpha = 0.25) +
  facet_wrap(~ empathy) +
  theme_bw() +
  labs(x = 'Total Bias',
       y = 'Average Reliability') +
  theme(legend.position = 'bottom')

empathy_plt1
empathy_plt2
```

An example model using the first empathy question, V202452, will be fit and assessed.

```{r}
library(VGAM)

anes_empathy1_df <- anes_empathy_df %>%
  filter(empathy == 'V202452')

# Modify case weights based on total responses to the response question
# Example weight = original weight * downsampling factor
n_samples <- nrow(anes_empathy1_df)
n_classes <- length(unique(anes_empathy1_df$value))
anes_empathy1_df_class_wts <- anes_empathy1_df %>%
  group_by(value) %>%
  summarize(n_samples_j = n(),
            class_wts = n_samples / (n_classes * n_samples_j))

anes_empathy1_df <- anes_empathy1_df %>%
  left_join(anes_empathy1_df_class_wts,
            by = 'value') %>%
  mutate(wts = V200010b * class_wts)

# Fit null model
null_fit <- anes_empathy1_df %>%
  vglm(formula = value ~ 1,
       weights = wts,
            family = cumulative(link = 'logit',
                                parallel = TRUE))

# Model using average bias and reliability
fit <- anes_empathy1_df %>%
  vglm(formula = value ~ Avg_Rel + Avg_Bias,
       weights = wts,
            family = cumulative(link = 'logit',
                                parallel = TRUE))

# Model using the absolute value of average bias with a directional term
fit2 <- anes_empathy1_df %>%
  vglm(formula = value ~ Avg_Rel + Abs_Bias + Dir_Bias,
       weights = wts,
            family = cumulative(link = 'logit',
                                parallel = TRUE))

# Model using Total_Bias and no directional term
fit3 <- anes_empathy1_df %>%
  vglm(formula = value ~ Avg_Rel * Total_Bias,
       weights = wts,
            family = cumulative(link = 'logit',
                                parallel = TRUE))

logLik(null_fit)
logLik(fit)
logLik(fit2)
logLik(fit3)

# Compare to null model
logLik(fit3) - logLik(null_fit)

# deviance test for lack of fit
g2 = deviance(fit3)
df = df.residual(fit3)
1 - pchisq(g2, df)

# pearson test for lack of fit
e = residuals(fit3, type='pearson')
x2 = sum(e^2)
1 - pchisq(x2, df)

par(mfrow = c(2, 4))
plot(fit3)
par(mfrow = c(1, 1))

# Model results
anova(fit3, test = 'LR')
summary(fit3)

# Predictions
fit_preds <- predict(fit3, type = 'response')

preds <- apply(fit_preds, 1, which.max)

# Confusion matrix and accuracy of model
table(anes_empathy1_df$value,
      preds)

accuracy_vec(anes_empathy1_df$value,
             factor(preds,
                    levels = c(1, 2, 3, 4, 5)))

anes_empathy1_df %>%
  mutate(Dir_Tot_Bias = factor(Dir_Tot_Bias,
                           levels = c(-2, -1, 0, 1, 2)),
         value = factor(value,
                        levels = c(5, 4, 3, 2, 1))) %>%
ggplot(aes(y = Dir_Tot_Bias,
           fill = value)) +
  geom_bar(position = 'fill') +
  scale_y_discrete(labels = c('Left', 'Center-left', 'Center', 'Center-right', 'Right')) +
  theme_bw() +
  labs(x = 'Proportion',
       y = 'Bias leaning',
       fill = 'Response')
```


