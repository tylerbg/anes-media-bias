---
title: "ANES media bias"
author: "Tyler Garner"
date: "2022-12-29"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The American National Election Studies (ANES) surveys eligible U.S. voters before and after presidential elections on various topics. For the 2020 pre-election survey, new questions were added on topics such as sexual harassment, health insurance, identity politics, immigration, media trust, institutional legitimacy, campaigns, party images, trade tariffs, and tax policy. Data collection started in August 2020 and ended on election day, November 3rd, 2020.

Ad Fontes Media is a non-partisan group that rates media sources based on their political bias and reliability. The media bias project evaluates individual news articles, TV shows, and radio programs using a three-analyst rating system, each with different political leanings.

![Ad Fontes Chart](../references/images/ad-fontes-chart.png)

The purpose of the analysis is to combine data from the ANES survey with the Ad Fontes Media project to examine variations in empathy, family politics, self-censorship, and sexism based on the media bias and reliability scores of the media consumed by each respondent.

### Research Questions

1. Do responses to questions on empathy and family politics vary by party affiliation?
2. Are responses to questions on empathy and family politics associated with bias and reliability of media outlets?
3. Is there a relationship between responses to questions on empathy and family politics with social media usage?

4. Are any specific media outlets predicitve of empathy or emotion responses?

5. Do more biased media consumers vote in caucuses more often?

## Data

### Variables

#### Emotion

- *V201114* - are things in the country on track
- *V201115* - how hopeful R feels about how things are going in the country
- *V201116* - how afraid R feels about how things are going in the country
- *V201117* - how outraged R feels about how things are going in the country
- *V201118* - how angry R feels about how things are going in the country
- *V201119* - how happy R feels about how things are going in the country
- *V201120* - how worried R feels about how things are going in the country
- *V201121* - how proud R feels about how things are going in the country
- *V201122* - how irritated R feels about how things are going in the country
- *V201123* - how nervous R feels about how things are going in the country

#### Family relations and empathy

- *V202451* - how much have political differences hurt relationships w/family
- *V202452* - how often does R have concerned feelings for other racial/ethnic groups
- *V202453* - how often does R try to understand perspective of other racial/ethnic groups
- *V202454* - how often R imagines how they would feel before criticizing other groups
- *V202455* - how often R feels protective of someone due to race or ethnicity

#### Self-censorship

- *V201626* - need to be more sensitive talking or people too easily offended
- *V201627* - how often self censor

#### Sexism

- *V201639* - women interpret innocent remarks as sexist
- *V201640* - women seek to gain power by getting control over men

```{r load-libs-and-data, warning = FALSE}
library(tidyverse)

anes <- read_csv("data/raw/anes_timeseries_2020_csv_20220210.csv",
                 show_col_types = FALSE)
```

```{r anes-desc-stats}
dim(anes)
head(anes)
```

Create subsets of the ANES data set for the variables of interest.

```{r anes-subset}
# Pre- (a) and post-election (b) weights
anes_weights <- anes %>%
  select(V200010a:V200010b)

# Party affiliation, registration, and voting
anes_registration <- anes %>%
  select(V201018:V201021) %>%
  select(!V201018z)
         
# Family and emotion, empathy, self-censorship, sexism
anes_emotion <- anes %>%
  select(V201114:V201123, # emotion about the country
         V202451:V202456, # family and empathy
         V201626:V201627, # self-censorship
         V201639:V201640) # sexism

# Pre-election media responses
anes_media <- anes %>%
  select(V201630a:V201630r, # TV programs 1
         V201631a:V201631r, # TV programs 2
         V201633a:V201633r, # Radio programs
         V201634a:V201634c,V201634e:V201634f, V201634h,
         V201634j:V201634q, # Websites not included in online newspapers
         V201636a:V201636d) # Online newspapers

# Post-election social media responses
anes_social_media <- anes %>%
  select(V202541a:V202547) # Note there are post-election
```

### Impute non-respondants

The media variables are coded as:

* -9. Refused
* -5. Interview breakoff (sufficient partial IW)
* -1. Inapplicable
* 0. Not mentioned
* 1. Mentioned

The focus will be on the "Not mentioned" and "Mentioned" response types. The other responses will be set as missing and filled in as 0 or 1 based on the other non-response variables in the pre- and post-election survey questions. Random forest imputation will be used.

Random Forest Imputation is a statistical method used to fill in missing values in a dataset. It uses an ensemble of decision trees (a "forest") to predict missing values. The algorithm works by splitting the dataset into smaller subsets, and building a decision tree for each of these subsets. The final prediction for the missing value is obtained by combining the results of all trees. Random Forest Imputation has the advantage of being more robust to outliers and noise compared to other imputation methods and can handle both continuous and categorical variables.


```{r read-imputed}
anes_imputed <- readRDS('data/interim/missForest-imputed.RDS')
```

### Bias and Reliability EDA

Bring in the Ad Fontes Media data and print out the average Reliability and Bias scores for each type of media.  Also print out the number of media sources that have 'left', 'right', or 'center' Bias.  It will be assumed that 'center' is between a -5 and 5 Bias score.

```{r load-ad-fontes-media}
adfontes <- read_csv('data/raw/adfontes.csv') %>%
  mutate(Media = factor(Media)) %>%
  drop_na()

adfontes %>%
  group_by(Media) %>%
  summarize(mean_rel = mean(Reliability, na.rm = TRUE),
            mean_bias = mean(Bias, na.rm = TRUE))

# Print the number of media sources with right, left, or center bias
adfontes %>%
  mutate(side = case_when(Bias > 10 ~ 'Right',
                          Bias < -10 ~ 'Left',
                          TRUE ~ 'Center')) %>%
  group_by(side) %>%
  summarize(n = n())
```



```{r adfontes-bias-rel-corr}
adfontes %>%
  pivot_longer(c(Bias, Reliability)) %>%
  ggplot(aes(x = value)) +
    geom_histogram(bins = 15) +
    facet_wrap(~ name,
               scales = 'free') +
    theme_classic()


ggplot(adfontes,
       aes(x = Bias,
           y = Reliability,
           color = Media)) +
  geom_point(alpha = 0.5) +
  theme_bw() +
  theme(legend.position = 'bottom')

# Create a linear model predicting Reliability by the abs val of Bias
bias_rel_fit <- summary(lm(Reliability ~ abs(Bias),
                   data = adfontes))

ggplot(adfontes,
       aes(x = abs(Bias),
           y = Reliability,
           color = Media)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = bias_rel_fit$coefficients[2, 1],
              intercept = bias_rel_fit$coefficients[1, 1],
              lty = 'dashed') +
  annotate('text',
           x = 22.5,
           y = 40,
           label = paste0('r^2 = ', round(bias_rel_fit$r.squared, 3),
                          '\np < 0.001')) +
  theme_bw() +
  theme(legend.position = 'bottom')
```

The non-transformed distributions of the Reliability vs Bias scores are curvi-linear while when taking the absolute value of Bias it becomes strongly linear.  This suggests that there is a strong relationship between Reliability and Bias, regardless if the Bias is 'left' or 'right', and it appears that this relationship stays trued independent of the type of media.

The ANES media variables will be filtered so that only those media variabes that have Bias and Reliability scores from Ad Fontes Media are included.  To note this was not done prior to imputation as the full variable set could be important for accurately predicting missing values in the bagged tree imputation.

```{r keep-adfontes-vars}
# Keep only the media vars that have Reliability and Bias scores
media_codes <- adfontes %>%
  drop_na() %>%
  filter(Code != 'V201634d',
         Code != 'V201634i',
         Code != 'V201634g') %>%
  pull(Code)
  
anes_imputed_media <- anes_imputed$ximp %>%
  select(all_of(media_codes)) %>%
  mutate(across(everything(), as.numeric))
```

The total, average, and median Bias and Reliability scores for the media consumed by each participant will be calculated.  Media not consumed (value of 0) will not be included in the calculations.  Bias will also be left as-is so that respondents who consume media on both sides can be centered (toward 0).

```{r bias-rel-sum-stats}
# Multiply col-wise to get the Bias and Reliability within each column
anes_imputed_media_bias <- anes_imputed_media *
  adfontes$Bias[match(names(anes_imputed_media),
                      adfontes$Code)][col(anes_imputed_media)]

anes_imputed_media_rel <- anes_imputed_media *
  adfontes$Reliability[match(names(anes_imputed_media),
                             adfontes$Code)][col(anes_imputed_media)]

anes_imputed_media$Total_Bias <- rowSums(anes_imputed_media_bias)
anes_imputed_media$Total_Rel <- rowSums(anes_imputed_media_rel)

# Get the average Bias and Reliability based on the media consumed for each respondant
# This will create NaN values for respondents with all 0 values
anes_imputed_media$Avg_Bias <- anes_imputed_media$Total_Bias / rowSums(anes_imputed_media_bias != 0)
anes_imputed_media$Avg_Rel <- anes_imputed_media$Total_Rel / rowSums(anes_imputed_media_rel != 0)

anes_imputed_media$Median_Bias <- apply(anes_imputed_media_bias, 1, function(x) median(x[x !=0]))
anes_imputed_media$Median_Rel <- apply(anes_imputed_media_rel, 1, function(x) median(x[x != 0]))

# Replace NaN values with 0
anes_imputed_media <- anes_imputed_media %>%
  mutate(across(c(Avg_Bias, Avg_Rel), ~ replace(., is.nan(.), 0)),
         across(c(Median_Bias, Median_Rel), ~ replace(., is.na(.), 0)))


anes_imputed_media %>%
  select(Total_Bias:Median_Rel) %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x = value)) +
    geom_histogram(bins = 50) +
    facet_wrap(~ name, scales = 'free') +
    theme_classic()
```

```{r}
# Bind the weights, party affiliation, and empathy var columns
anes_to_model <- anes_registration %>%
  bind_cols(anes_weights, anes_emotion, anes_imputed_media)

# Plot the total number of respondents in each political affiliation
anes_to_model %>%
  select(V201018) %>%
  group_by(V201018) %>%
  summarize(n = n()) %>%
  ggplot(aes(x = ordered(V201018),
             y = n)) +
    geom_col() +
    scale_x_discrete(labels = c('Refused', 'Dont Know', 'Inapplicable', 'D', 'R', 'I', 'Other')) +
    theme_classic()
```

Create a data frame in long format for plotting the weights, empathy, party affiliation, and bias/reliability variables.

```{r}
anes_plt_df <- anes_to_model %>%
  select(V200010a, V201018, V202451:V202455, Avg_Bias:last_col()) %>%
  pivot_longer(V202451:V202455,
               names_to = 'empathy',
               values_to = 'value') %>%
  filter(value > 0) %>%
  mutate(value = ordered(value))

# Plot Reliability vs Bias for political party affiliation
anes_plt_df %>%
  select(!c(empathy, value)) %>%
  distinct() %>%
  filter(V201018 >= -1) %>%
  ggplot(aes(x = Median_Bias,
             y = Median_Rel,
             color = ordered(V201018))) +
  geom_point(alpha = 0.25)

# Do the same plot but with only R, D, and I and recolored
anes_plt_df %>%
  select(!c(empathy, value)) %>%
  distinct() %>%
  filter(V201018 %in% c(1, 2, 4)) %>%
  ggplot(aes(x = Median_Bias,
             y = Median_Rel,
             color = ordered(V201018))) +
  geom_point(alpha = 0.25) +
  scale_color_manual(values = c('blue', 'red', 'grey10'))

# Plot Reliability vs Bias for each of the fampol and empathy
anes_plt_df %>%
  ggplot(aes(x = Median_Bias,
             y = Median_Rel,
             color = value)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~ empathy)
```




## Statistical Analysis

```{r}
library(rstatix)

# Kruskal-Wallis test to see if respondents vary on empathy based on political party
anes_plt_df %>%
  filter(V201018 %in% c(1, 2, 4)) %>%
  group_by(empathy) %>%
  kruskal_test(V201018 ~ value) %>%
  adjust_pvalue()

# Kruskal-Wallis test to see if respondents vary on empathy based on median Bias
anes_plt_df %>%
  filter(V201018 %in% c(1, 2, 4)) %>%
  group_by(empathy) %>%
  kruskal_test(Median_Bias ~ value) %>%
  adjust_pvalue()

# Kruskal-Wallis test to see if respondents vary on empathy based on median Reliability
anes_plt_df %>%
  filter(V201018 %in% c(1, 2, 4)) %>%
  group_by(empathy) %>%
  kruskal_test(Median_Rel ~ value) %>%
  adjust_pvalue()


anes_plt_df %>%
  filter(V201018 %in% c(1, 2, 4)) %>%
  group_by(V201018, empathy, value) %>%
  summarize(n = n()) %>%
  ggplot(aes(x = ordered(V201018),
             y = n,
             fill = value)) +
    geom_col(position = 'fill') +
    facet_wrap(~ empathy)
  
```

```{r}
fampol_diffhurt <- anes_plt_df %>%
  filter(empathy == 'V202451',
         Median_Bias != 0 & Median_Rel != 0)

# Example weight = original weight * downsampling factor
n_samples <- nrow(fampol_diffhurt)
n_classes <- length(unique(fampol_diffhurt$value))
fampol_diffhurt_case_wts <- fampol_diffhurt %>%
  group_by(value) %>%
  summarize(n_samples_j = n(),
            case_wts = n_samples / (n_classes * n_samples_j))

fampol_diffhurt$case_wts <- fampol_diffhurt %>%
  select(value) %>%
  mutate(case_wts = case_when(value == 1 ~ fampol_diffhurt_case_wts$case_wts[1],
                              value == 2 ~ fampol_diffhurt_case_wts$case_wts[2],
                              value == 3 ~ fampol_diffhurt_case_wts$case_wts[3],
                              value == 4 ~ fampol_diffhurt_case_wts$case_wts[4],
                              value == 5 ~ fampol_diffhurt_case_wts$case_wts[5])) %>%
  pull(case_wts)

fampol_diffhurt$wts <- fampol_diffhurt$V200010b * fampol_diffhurt$case_wts

library(VGAM)

fit <- vglm(formula = value ~ Median_Bias * Median_Rel,
            data = fampol_diffhurt,
            weights = wts,
            family = cumulative(parallel = TRUE))

summary(fit)

fit_preds <- predict(fit, type = 'response')

preds <- apply(fit_preds, 1, which.max)

table(fampol_diffhurt %>%
        pull(value),
      preds)

## Get table of coefficients
coef_table <- coef(summary(fit))

## Estimate and print p-values
p <- pnorm(abs(coef_table[, "z value"]), lower.tail = FALSE) * 2

coef_table <- cbind(coef_table, "p value" = round(p, 4))

coef_table

ggplot(fampol_diffhurt,
       aes(x = Median_Bias * (max(Median_Rel) - Median_Rel),
           y = value)) +
  geom_boxplot()

anova(fit)

logLik(fit)
```

### Random Forest

```{r}
library(tidymodels)

famdiff_rfor_df <- anes_to_model %>%
  select(V200010a, V202451, V201630b:V201636d) %>%
  filter(V202451 > 0) %>%
  mutate(V202451 = ordered(V202451))

# Example weight = original weight * downsampling factor
n_samples <- nrow(famdiff_rfor_df)
n_classes <- length(unique(famdiff_rfor_df$V202451))
famdiff_rfor_case_wts <- famdiff_rfor_df %>%
  group_by(V202451) %>%
  summarize(n_samples_j = n(),
            case_wts = n_samples / (n_classes * n_samples_j))
s
famdiff_rfor_df$case_wts <- famdiff_rfor_df %>%
  select(V202451) %>%
  mutate(case_wts = case_when(V202451 == 1 ~ famdiff_rfor_case_wts$case_wts[1],
                              V202451 == 2 ~ famdiff_rfor_case_wts$case_wts[2],
                              V202451 == 3 ~ famdiff_rfor_case_wts$case_wts[3],
                              V202451 == 4 ~ famdiff_rfor_case_wts$case_wts[4],
                              V202451 == 5 ~ famdiff_rfor_case_wts$case_wts[5])) %>%
  pull(case_wts)

famdiff_rfor_df$case_wts <- famdiff_rfor_df$V200010a * famdiff_rfor_df$case_wts

famdiff_rfor_df <- famdiff_rfor_df %>%
  select(!V200010a) %>%
  mutate(case_wts = importance_weights(case_wts))

famdiff_rfor_df_split <- initial_split(famdiff_rfor_df,
                                       prop = 3/4)

famdiff_rfor_df_train <- training(famdiff_rfor_df_split)
famdiff_rfor_df_test <- testing(famdiff_rfor_df_split)

cv_folds <- vfold_cv(famdiff_rfor_df_train,)

rfor_recipe <- recipe(V202451 ~ .,
                      data = famdiff_rfor_df)

rfor_model <- rand_forest(mtry = tune(),
                          trees = tune(),
                          min_n = tune()) %>%
  set_engine('ranger',
             num.threads = 14,
             importance = "impurity") %>%
  set_mode('classification')

rfor_params <- rfor_model %>%
  extract_parameter_set_dials() %>%
  update(mtry = mtry(c(1, 50)))

rfor_wf <- workflow() %>%
  add_recipe(rfor_recipe) %>%
  add_model(rfor_model) %>%
  add_case_weights(case_wts)

set.seed(4960)
rfor_bayes_tune <- rfor_wf %>%
  tune_bayes(resamples = cv_folds,
             iter = 50,
             param_info = rfor_params,
             metrics = metric_set(roc_auc),
             initial = 5,
             control = control_bayes(verbose = TRUE,
                                     verbose_iter = TRUE))

select_best(rfor_bayes_tune)

final_params <- select_best(rfor_bayes_tune) %>%
  select(!.config)

rfor_final_wf <- rfor_wf %>%
  finalize_workflow(final_params)

rfor_fit <- rfor_final_wf %>%
  fit(famdiff_rfor_df_train)

rfor_preds <- predict(rfor_fit,
                      new_data = famdiff_rfor_df_test)

table(obs = famdiff_rfor_df_test %>% pull(V202451),
      pred = rfor_preds$.pred_class)

accuracy_vec(famdiff_rfor_df_test %>% pull(V202451) %>% factor(),
             rfor_preds$.pred_class)

library(vip)

rfor_fit %>%
  extract_fit_parsnip() %>%
  vip()
```
